# 🛠️ Defect Detection Test – iOS App

An iOS application that detects real-world structural defects (like **cracks**, **mold**, and **water damage**) using on-device **YOLOv8 + CoreML** models.
Built with **SwiftUI**, powered by **CoreML**, and optimized for real-time detection.

---

## 📂 Project Structure

```
defectdettest/
│
├── BoundingBoxView.swift
├── ContentView.swift
├── defect_detect.pt                        # PyTorch model used for training
├── DefectDetectionModel.mlmodel           # CoreML models (converted from YOLOv8)
├── defect_detect.mlpackage/               # Final .mlpackage for inference
├── defectdettestApp.swift                 # App entry point
├── Assets.xcassets/
├── Item.swift
│
├── defectdettest.xcodeproj/               # Xcode project
├── defectdettestTests/                    # Unit tests
└── defectdettestUITests/                  # UI tests
```

---

## 🚀 Features

* 🔍 **Real-Time Object Detection** using YOLOv8 (CoreML conversion)
* 🖼️ **Image Selection & Processing** from gallery or camera
* 🔁 **Fallback Class Labels** if model metadata is unavailable
* 🧠 Works completely **on-device** – no server required

---

## 🔑 Key Files

| File                           | Description                                       |
| ------------------------------ | ------------------------------------------------- |
| `defectdettestApp.swift`       | SwiftUI app entry point                           |
| `ContentView.swift`            | UI logic for model selection and image prediction |
| `defect_detect.pt`             | YOLOv8 PyTorch model before CoreML conversion     |
| `DefectDetectionModel.mlmodel` | CoreML-ready YOLOv8 model                         |
| `defect_detect.mlpackage`      | Optimized model package for iOS inference         |

---

## ⚙️ Setup Instructions

1. **Clone the repository**

   ```bash
   git clone https://github.com/your-username/defectdettest.git
   cd defectdettest
   ```

2. **Open the Xcode project**

   ```bash
   open defectdettest.xcodeproj
   ```

3. **Build & run** on a simulator or physical device.

---

## 🧪 Usage

1. Launch the app 📱
2. Select or capture an image 📸
3. The model runs detection and shows **bounding boxes + labels** 🧠
4. Tap boxes for **defect details** (optional extension)

---

## 📦 Dependencies

* **CoreML** – Model inference on iOS
* **SwiftUI** – Declarative UI framework
* *(Optional)*: AVFoundation for video support

---

## 🧠 Model Details

* **Model**: YOLOv8 (converted to CoreML)
* **Input Size**: `640x640` RGB
* **Output**: Bounding Boxes + Class Labels + Confidence Scores
* **Defect Classes**: Cracks, Water Damage, Mold, Pipe Leak, etc.

---

## 📜 License

Model is licensed under **AGPL-3.0**.
Please refer to [Ultralytics License](https://ultralytics.com/license) for full details.
